{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXHEqRjEzExB"
      },
      "source": [
        "# **ANÁLISIS DEL ESTADO Y EVOLUCIÓN DE LOS EMBALSES DE AGUA NACIONALES**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuSIBbMbzm5L"
      },
      "source": [
        "Este notebook explica el trabajo de preprocesamiento, análisis y modelado para entender el estado y la evolución de la reserva hídrica en España. A lo largo del proyecto, se trabajará con datos históricos y geográficos para explorar tendencias, identificar patrones y realizar predicciones sobre el agua embalsada en el país.\n",
        "\n",
        "Antes de empezar con los análisis y modelos, se seguirán los siguientes pasos:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWxD9_583Jb6"
      },
      "source": [
        "# Pasos que se seguirán para preparar los datos\n",
        "1. Importación de librerías y configuración inicial.\n",
        "2. Carga de archivos de datos a utilizar.\n",
        "3. Modificación y ajuste de las variables.\n",
        "4. Detección y tratamiento de datos ausentes (NAs).\n",
        "5. Generación de nuevas variables.\n",
        "6. Enriquecimiento del dataset con datos climáticos y/o económicos.\n",
        "7. Análisis exploratorio de los datos.\n",
        "8. Modelado predictivo y comparativa de modelos.\n",
        "9. Visualización de resultados.\n",
        "10. Creación de tablas y exportación de datos.\n",
        "11. Desarrollo de un prototipo interactivo.\n",
        "12. Conclusiones y recomendaciones.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1sEcS8FZnqZ"
      },
      "source": [
        "## 1. Importación de librerias\n",
        "Lo primero que debemos hacer es instalar y cargar las librerías necesarias para el manejo, análisis y visualización de datos, además de configurar el entorno de trabajo. Usaremos algunas de las librerías más populares de Python para garantizar un flujo de trabajo eficiente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b78JNY2_1-Py",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e59a739-78e4-408b-c8b3-d78098a8a9d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estilos disponibles en Matplotlib: ['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'petroff10', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n",
            "Librerías cargadas y entorno configurado correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Importamos las librerías a utilizar\n",
        "import pandas as pd  # Manejo y análisis de datos\n",
        "import numpy as np  # Operaciones matemáticas\n",
        "import matplotlib.pyplot as plt  # Visualización básica\n",
        "import seaborn as sns  # Visualización estadística avanzada\n",
        "from sklearn.model_selection import train_test_split  # Dividir datos para modelado\n",
        "from sklearn.linear_model import LinearRegression  # Modelo de regresión lineal\n",
        "from statsmodels.tsa.arima.model import ARIMA  # Modelos ARIMA para series temporales\n",
        "\n",
        "# Configuramos el entorno\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")  # Ignoramos warnings para evitar distracciones\n",
        "\n",
        "# Configuración de pandas para mostrar más datos\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", 100)\n",
        "\n",
        "# Configuramos el estilo de los gráficos\n",
        "print(\"Estilos disponibles en Matplotlib:\", plt.style.available)  # Listamos estilos disponibles\n",
        "plt.style.use(\"ggplot\")  # Cambiamos a un estilo seguro como 'ggplot'\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "plt.rcParams[\"font.size\"] = 12\n",
        "\n",
        "# Confirmación de configuración\n",
        "print(\"Librerías cargadas y entorno configurado correctamente.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBvsEI0n3Wcx"
      },
      "source": [
        "## 2. Carga de datos\n",
        "\n",
        "Para realizar el análisis y predicciones sobre el agua embalsada, es necesario cargar los datasets que contienen información histórica y geográfica de los embalses. Estos archivos están alojados en un repositorio de GitHub.\n",
        "\n",
        "Archivos a cargar:\n",
        "Datos embalses: Contiene datos históricos sobre el volumen de agua embalsada en diferentes fechas.\n",
        "Embalses enriquecido: Contiene información geográfica y detalles adicionales sobre los embalses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QH_QWctm3ZRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9675b954-92b9-4f13-ee7d-6eee259a9af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos embalses cargados con éxito.\n",
            "Embalses enriquecido cargado con éxito.\n",
            "\n",
            "Resumen de 'Datos embalses':\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 637606 entries, 0 to 637605\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count   Dtype         \n",
            "---  ------          --------------   -----         \n",
            " 0   AMBITO_NOMBRE   637606 non-null  object        \n",
            " 1   EMBALSE_NOMBRE  637606 non-null  object        \n",
            " 2   FECHA           637606 non-null  datetime64[ns]\n",
            " 3   AGUA_TOTAL      637604 non-null  object        \n",
            " 4   AGUA_ACTUAL     637604 non-null  object        \n",
            " 5   ELECTRICO_FLAG  637606 non-null  int64         \n",
            "dtypes: datetime64[ns](1), int64(1), object(4)\n",
            "memory usage: 29.2+ MB\n",
            "None\n",
            "\n",
            "Primeras filas de 'Datos embalses':\n",
            "  AMBITO_NOMBRE EMBALSE_NOMBRE      FECHA AGUA_TOTAL AGUA_ACTUAL  \\\n",
            "0    Miño - Sil     Albarellos 1988-01-05      91,00       32,00   \n",
            "1    Miño - Sil     Albarellos 1988-01-12      91,00       44,00   \n",
            "2    Miño - Sil     Albarellos 1988-01-19      91,00       42,00   \n",
            "3    Miño - Sil     Albarellos 1988-01-26      91,00       43,00   \n",
            "4    Miño - Sil     Albarellos 1988-02-02      91,00       65,00   \n",
            "\n",
            "   ELECTRICO_FLAG  \n",
            "0               1  \n",
            "1               1  \n",
            "2               1  \n",
            "3               1  \n",
            "4               1  \n",
            "\n",
            "Resumen de 'Embalses enriquecido':\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 367 entries, 0 to 366\n",
            "Data columns (total 33 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   X                          367 non-null    float64\n",
            " 1   Y                          367 non-null    float64\n",
            " 2   INFORME                    367 non-null    object \n",
            " 3   ID_INFRAES                 367 non-null    int64  \n",
            " 4   CODIGO                     367 non-null    int64  \n",
            " 5   NOMBRE                     367 non-null    object \n",
            " 6   EMBALSE                    367 non-null    object \n",
            " 7   Wikidata                   187 non-null    object \n",
            " 8   Google Knowledge Graph ID  115 non-null    object \n",
            " 9   Google                     115 non-null    object \n",
            " 10  OpenStreetMap relation ID  36 non-null     float64\n",
            " 11  OpenStreetMap              36 non-null     object \n",
            " 12  image                      157 non-null    object \n",
            " 13  Imagen                     157 non-null    object \n",
            " 14  FASE                       367 non-null    object \n",
            " 15  TITULAR                    367 non-null    object \n",
            " 16  CATEGORIA                  367 non-null    object \n",
            " 17  CAUCE                      359 non-null    object \n",
            " 18  DEMARC                     367 non-null    object \n",
            " 19  PROVINCIA                  367 non-null    object \n",
            " 20  CCAA                       367 non-null    object \n",
            " 21  TIPO                       367 non-null    object \n",
            " 22  USUARIOS                   353 non-null    object \n",
            " 23  USO                        367 non-null    object \n",
            " 24  SUP_CUENCA                 166 non-null    float64\n",
            " 25  AP_M_ANUAL                 169 non-null    float64\n",
            " 26  NMN_CAPAC                  367 non-null    float64\n",
            " 27  NMN_SUP                    363 non-null    float64\n",
            " 28  COTA_CORON                 184 non-null    float64\n",
            " 29  ALT_CIMIEN                 184 non-null    float64\n",
            " 30  LONG_CORON                 184 non-null    float64\n",
            " 31  CAP_AL_NAE                 323 non-null    float64\n",
            " 32  CAP_MAX_DF                 298 non-null    float64\n",
            "dtypes: float64(12), int64(2), object(19)\n",
            "memory usage: 94.7+ KB\n",
            "None\n",
            "\n",
            "Primeras filas de 'Embalses enriquecido':\n",
            "           X         Y                                            INFORME  \\\n",
            "0  36.153615 -5.649731  https://sig.mapama.gob.es/WebServices/clientew...   \n",
            "1  42.722873 -0.462684  https://sig.mapama.gob.es/WebServices/clientew...   \n",
            "2  38.095562 -3.831098  https://sig.mapama.gob.es/WebServices/clientew...   \n",
            "3  43.277118 -1.773747  https://sig.mapama.gob.es/WebServices/clientew...   \n",
            "4  38.060263 -1.487653  https://sig.mapama.gob.es/WebServices/clientew...   \n",
            "\n",
            "   ID_INFRAES   CODIGO      NOMBRE               EMBALSE  \\\n",
            "0        1364  5110039   ALMODOVAR  Embalse de Almodóvar   \n",
            "1        2482  9220067  IBON DE IP          Ip reservoir   \n",
            "2        1543  5230007     ZOCUECA               ZOCUECA   \n",
            "3          84  1310009   SAN ANTON             SAN ANTON   \n",
            "4        2057  7300021  CIERVA, LA  Embalse de la Cierva   \n",
            "\n",
            "                                   Wikidata Google Knowledge Graph ID Google  \\\n",
            "0    https://www.wikidata.org/wiki/Q5369429                       NaN    NaN   \n",
            "1   https://www.wikidata.org/wiki/Q23999337                       NaN    NaN   \n",
            "2                                       NaN                       NaN    NaN   \n",
            "3                                       NaN                       NaN    NaN   \n",
            "4  https://www.wikidata.org/wiki/Q107738426                       NaN    NaN   \n",
            "\n",
            "   OpenStreetMap relation ID OpenStreetMap image Imagen         FASE  \\\n",
            "0                        NaN           NaN   NaN    NaN  Explotación   \n",
            "1                        NaN           NaN   NaN    NaN  Explotación   \n",
            "2                        NaN           NaN   NaN    NaN  Explotación   \n",
            "3                        NaN           NaN   NaN    NaN  Explotación   \n",
            "4                        NaN           NaN   NaN    NaN  Explotación   \n",
            "\n",
            "                                             TITULAR CATEGORIA  \\\n",
            "0  JUNTA DE ANDALUCIA. AGENCIA ANDALUZA DEL AGUA\\...         A   \n",
            "1  ELECTRICAS REUNIDAS DE ZARAGOZA\\ncorporacion a...         A   \n",
            "2  ESTADO\\nCONFEDERACION HIDROGRAFICA DEL GUADALQ...         A   \n",
            "3              MANCOMUNIDAD DE SERVICIOS DE TXINGUDI         A   \n",
            "4      ESTADO\\nCONFEDERACION HIDROGRAFICA DEL SEGURA         A   \n",
            "\n",
            "            CAUCE               DEMARC PROVINCIA                        CCAA  \\\n",
            "0   RÍO ALMODÓVAR  GUADALETE Y BARBATE     Cádiz                   Andalucía   \n",
            "1  BARRANCO DE IP                 EBRO    Huesca                      Aragón   \n",
            "2    RÍO  RUMBLAR         GUADALQUIVIR      Jaén                   Andalucía   \n",
            "3      RIO ENDARA  CANTABRICO ORIENTAL   Navarra  Comunidad Foral de Navarra   \n",
            "4        RIO MULA               SEGURA    Murcia            Región de Murcia   \n",
            "\n",
            "                                                TIPO USUARIOS  \\\n",
            "0    Presa de fábrica de gravedad (hormigón vibrado)     -\\n-   \n",
            "1  Presa de materiales sueltos zonificada o de nú...        -   \n",
            "2    Presa de fábrica de gravedad (hormigón vibrado)     -\\n-   \n",
            "3  Presa de materiales sueltos de pantalla de hor...        -   \n",
            "4                    Presa de fábrica de mampostería      NaN   \n",
            "\n",
            "                                       USO  SUP_CUENCA  AP_M_ANUAL  NMN_CAPAC  \\\n",
            "0  Abastecimiento\\nDefensa frente avenidas        16.5        0.00      5.000   \n",
            "1                           Hidroeléctrico         8.0        4.56      5.000   \n",
            "2  Abastecimiento\\nDefensa frente avenidas         NaN         NaN      5.000   \n",
            "3                           Abastecimiento        10.5       20.00      5.091   \n",
            "4  Abastecimiento\\nDefensa frente avenidas         NaN         NaN      5.130   \n",
            "\n",
            "    NMN_SUP  COTA_CORON  ALT_CIMIEN  LONG_CORON  CAP_AL_NAE  CAP_MAX_DF  \n",
            "0  650200.0       107.2        40.0       126.0         0.0         NaN  \n",
            "1  270000.0      2119.0        31.0       158.0         0.0       20.00  \n",
            "2  480000.0         NaN         NaN         NaN         0.0         NaN  \n",
            "3  278170.0       247.0        56.8       210.0         0.0      150.48  \n",
            "4  432000.0         NaN         NaN         NaN         0.0   366000.00  \n"
          ]
        }
      ],
      "source": [
        "# Importamos pandas para manejar los datasets\n",
        "import pandas as pd\n",
        "\n",
        "# URLs de los archivos en el repositorio de GitHub\n",
        "url_historicos = \"https://raw.githubusercontent.com/cddogaru/Proyecto-de-Computaci-n-I/main/Datos%20embalses.xlsx\"\n",
        "url_geo = \"https://raw.githubusercontent.com/cddogaru/Proyecto-de-Computaci-n-I/main/Embalses_enriquecido.xlsx\"\n",
        "\n",
        "# Cargar los datasets desde GitHub\n",
        "try:\n",
        "    # Cargar archivo histórico\n",
        "    embalses = pd.read_excel(url_historicos)\n",
        "    print(\"Datos embalses cargados con éxito.\")\n",
        "\n",
        "    # Cargar archivo geográfico\n",
        "    embalses_geo = pd.read_excel(url_geo)\n",
        "    print(\"Embalses enriquecido cargado con éxito.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar los datasets: {e}\")\n",
        "\n",
        "# Resumen de los datos históricos\n",
        "print(\"\\nResumen de 'Datos embalses':\")\n",
        "print(embalses.info())\n",
        "print(\"\\nPrimeras filas de 'Datos embalses':\")\n",
        "print(embalses.head())\n",
        "\n",
        "# Resumen de los datos geográficos\n",
        "print(\"\\nResumen de 'Embalses enriquecido':\")\n",
        "print(embalses_geo.info())\n",
        "print(\"\\nPrimeras filas de 'Embalses enriquecido':\")\n",
        "print(embalses_geo.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3w0d8RFoUcib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69yoSvTMOudb"
      },
      "source": [
        "Estructura Documentada del Punto 2\n",
        "\n",
        "1. Explicación Breve: Introducimos el propósito de cargar los datos y describimos los archivos utilizados.\n",
        "\n",
        "2. Cargar Datos: Se usan las URLs de los archivos en GitHub para cargarlos directamente en el entorno Colab.\n",
        "\n",
        "3. Validación:\n",
        "\n",
        "  *   Se usa info() para mostrar un resumen de los datos (columnas, tipos,  \n",
        "    valores nulos).\n",
        "  *   Se usa head() para visualizar las primeras filas y asegurarnos de que los datos se cargaron correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSaj9zvDWEuh"
      },
      "source": [
        "## 3. Modificación y ajuste de las variables\n",
        "\n",
        "Una de las primeras acciones que hay que realizar tras la carga de los datos, es verificar las variables y **modificarlas buscando que se adecuen a nuestras tablas de trabajo**. En este caso, renombraremos , modificaremos el tipo , eliminaremos las que no nos interesan para el análisis y sustituiremos los valores decimales con coma por punto.\n",
        "\n",
        "*   Para renombrar las variables utilizamos la función [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n",
        "\n",
        "*   Para convertir el nombre de una variable a letras minúsculas utilizamos la función [.str.lower()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html?)\n",
        "\n",
        "*   Para sustituir los valores decimales con coma por punto utilizamos la función [.str.replace()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html?)\n",
        "\n",
        "*   Para modificar el tipo de variable utilizamos la función [.astype()](https://pandas.pydata.org/docs/reference/api/pandas.Series.astype.html?)\n",
        "\n",
        "*    Para modificar el tipo de variable a una fecha utilizamos la función [.to_datetime()](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)\n",
        "\n",
        "*   Para eliminar una variable utilizamos la función [.drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1LXtAXNUAa8"
      },
      "source": [
        "Para el dataset **\"embalses\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAXtcZzVWEHA"
      },
      "outputs": [],
      "source": [
        "# Renombramos las variables\n",
        "embalses = embalses.rename(columns= {\"AMBITO_NOMBRE\": \"demarcacion_hidrografica\", \"AGUA_TOTAL\": \"capacidad_total\", \"AGUA_ACTUAL\": \"volumen_actual\"})\n",
        "\n",
        "# Modificamos el nombre de los encabezados a letras minúsculas\n",
        "embalses= embalses.rename(columns=str.lower)\n",
        "\n",
        "# Sustituimos los valores decimales con coma por punto\n",
        "embalses[\"capacidad_total\"] = embalses[\"capacidad_total\"].str.replace(\",\",\".\")\n",
        "embalses[\"volumen_actual\"] = embalses[\"volumen_actual\"].str.replace(\",\",\".\")\n",
        "\n",
        "# Transformamos el tipo de variable a floats\n",
        "embalses[\"capacidad_total\"]= embalses[\"capacidad_total\"].astype(float)\n",
        "embalses[\"volumen_actual\"] = embalses[\"volumen_actual\"].astype(float)\n",
        "\n",
        "# Transformamos el tipo de variable a fecha dandole el formato deseado\n",
        "embalses[\"fecha\"] = pd.to_datetime(embalses[\"fecha\"], format = \"%d/%m/%Y\")\n",
        "\n",
        "# Eliminamos las columnas que contienen variables que no interesan para el análisis\n",
        "embalses = embalses.drop(axis=1, columns= [\"electrico_flag\"])\n",
        "embalses.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY8mEdeOUBk7"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que las **modificaciónes y ajustes** de las variables se ha realizado correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNeXkO5GFpdt"
      },
      "source": [
        "Para el sataset **\"embalses_geo\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUSV60R2FdHJ"
      },
      "outputs": [],
      "source": [
        "# Filtramos las variables que nos interesan para el análisis\n",
        "embalses_geo = embalses_geo[[\"X\",\"Y\",\"NOMBRE\",\"DEMARC\",\"CAUCE\",\"Google\",\"OpenStreetMap\",\"Wikidata\", \"image\",\"Imagen\", \"USO\", \"PROVINCIA\"]]\n",
        "\n",
        "# Renombramos las variables\n",
        "embalses_geo = embalses_geo.rename(columns= {\"DEMARC\": \"demarcación_hidrografica\",\"NOMBRE\":\"embalse_nombre\"})\n",
        "\n",
        "# Modificamos el nombre de los encabezados a letras minúsculas\n",
        "embalses_geo= embalses_geo.rename(columns=str.lower)\n",
        "embalses_geo.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cijcjaZwUh-9"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que las **modificaciónes y ajustes** de las variables se ha realizado correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTwy42eMNd-Y"
      },
      "source": [
        "## 4. Detención y tratamiento de datos ausentes (NAs)\n",
        "\n",
        "La presencia de datos ausentes es una **problemática habitual** en muchos conjuntos de datos. Tratar con conjuntos de datos en los que existan puede generar problemas durante los posteriores análisis.\n",
        "\n",
        "\n",
        "*   Para buscar los datos ausentes en cada variable utilizamos la función [is.null()](https://pandas.pydata.org/docs/reference/api/pandas.isnull.html?)\n",
        "\n",
        "*   Para eliminar los datos ausentes en el dataset utilizamos la función [.drop.na()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKv72K34Vyjx"
      },
      "source": [
        "Para el dataset **\"embalses\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea9NGqiOs-AU"
      },
      "outputs": [],
      "source": [
        "# Búsqueda de datos ausentes.\n",
        "embalses.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBBbKHW6fReA"
      },
      "source": [
        "Obtenemos la **suma de valores nulos por variable**. En este caso observamos que dentro del dataset hay 2 valores nulos en la columna \"capacidad_total\" y otros 2 en la columna \"volumen_actual\". Debido a que el conjunto de datos es lo suficientemente grande y no se pierde información relevante al **eliminar** esas filas, procedemos a eliminarlas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAX5NMINZWFs"
      },
      "outputs": [],
      "source": [
        "# Eliminamos las filas con valores ausentes\n",
        "embalses = embalses.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVqRqL81WLg0"
      },
      "source": [
        "Para el dataset **\"embalses_geo\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igP2vqT6HHC8"
      },
      "outputs": [],
      "source": [
        "# Búsqueda de datos ausentes\n",
        "embalses_geo.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpK6vf4WRHU"
      },
      "source": [
        "Obtenemos la suma de valores nulos por variable. En este caso observamos que dentro del dataset hay **grandes cantidades** de valores nulos en las columnas \"google\", \"openstreetmap\" y \"wikidata\". En esta ocasión **no se eliminan** las filas que presentan valores nulos ya que significaría una pérdida importante de la información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahgjmOPhYEs9"
      },
      "source": [
        "## 5. Generación de nuevas variables\n",
        "\n",
        "Una acción muy común en el análisis de datos, es la creación de nuevas variables a partir de las variables existentes en los datos, ya que en ocasiones interesa **trabajar con datos calculados**, en lugar de los datos de origen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcU_jmDQXFYK"
      },
      "source": [
        "Para el dataset **\"embalses\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN3eKmDnXgKd"
      },
      "source": [
        "Creamos la variable **\"porcentaje_actual\"** dentro de\n",
        "una nueva columna con el valor del porcentaje de agua embalsado en cada momento sobre la capacidad total (porcentaje de llenado). Para ello se utilizan los datos de las variables \"volumen_actual\" y \"capacidad_total\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8VsCtWgYKWq"
      },
      "outputs": [],
      "source": [
        "# Generamos una nueva variable con el porcentaje de llenado del ambalse\n",
        "embalses[\"porcentaje_actual\"] = round(100*(embalses[\"volumen_actual\"]/embalses[\"capacidad_total\"]), 2)\n",
        "embalses.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl1gg4S3oPt-"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que la **nueva variable \"porcentaje_actual\"** ha sido creada correctamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwT0qxA4Yaoh"
      },
      "source": [
        "Dividimos la variable fecha en **dos nuevas variables** correspondientes a dos columnas, una con el año y la otra con el mes.\n",
        "\n",
        "*   Para obtener el valor del año y del mes de la variable fecha utilizamos las funciones [.dt.year](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html) y [.dt.month](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.month.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjVAPvSFYa5R"
      },
      "outputs": [],
      "source": [
        "# Generamos dos nuevas columnas a partir de la columna \"fecha\". Una con el año y la otra con el mes\n",
        "embalses[\"mes\"] = embalses[\"fecha\"].dt.month\n",
        "embalses[\"año\"] = embalses[\"fecha\"].dt.year\n",
        "embalses.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6t_RlGZosKU"
      },
      "source": [
        "Visualizamos las 5 primeras filas del dataset para comprobar que las **nuevas variables \"mes\" y \"año\"** han sido creadas correctamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeDUKGr0YCI-"
      },
      "source": [
        "Para el dataset **\"embalses_geo\"** realizamos los siguientes pasos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0mLsgfoYNy2"
      },
      "source": [
        "Creeamos la varible \"**coordenadas**\" uniendo las variables \"x\" e \"y\" y sustituimos caracteres que no son procesables por herramientas de visualización en las variables **\"uso\"** y **\"provincia\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W48sP6cKHvw9"
      },
      "outputs": [],
      "source": [
        "# Generamos una nueva variable con las coordenadas X e Y juntas\n",
        "embalses_geo[\"coordenadas\"] = embalses_geo['x'].astype(str)+\",\"+embalses_geo['y'].astype(str)\n",
        "\n",
        "# Sustituimos caracterres no procesables por herramientas de visualización\n",
        "embalses_geo[\"uso\"] = embalses_geo[\"uso\"].str.replace(\"\\n\", \",\")\n",
        "embalses_geo[\"provincia\"] = embalses_geo[\"provincia\"].str.replace(\"/\", \",\")\n",
        "embalses_geo.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xCoaHNmXvoH"
      },
      "source": [
        "Una vez hemos realizado el tratamiento previo de los datos desarrollado hasta ahora, pasamos a crear las **tablas de datos** para alimentar a la herramienta de visualización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfBA-fb5FoZw"
      },
      "source": [
        "## 6. Creación de tabla para visualización \"Evolución histórica de la reserva hídrica entre los años 2012 y 2022\"\n",
        "Generamos la primera tabla de datos preparada para alimentar la herramienta de visualización que vamos a utilizar, Google Data Studio.\n",
        "\n",
        "Para ello **filtramos** el dataset para obtener los datos entre el **01/01/2012 y el 01/01/2022**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K9jeK3KJUnM"
      },
      "outputs": [],
      "source": [
        "# Filtramos el dataset para quedarnos con los valores históricos del 2012 al 2022\n",
        "tabla_lin = embalses[(embalses[\"fecha\"]>\"01/01/2012\") & (embalses[\"fecha\"]<\"01/01/2022\")]\n",
        "tabla_lin.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G5WP4Q3Ji5i"
      },
      "source": [
        "Visualizamos las 5 primeras filas de la tabla y comprobamos que se ha **filtrado** correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsWcz4LQ16dj"
      },
      "source": [
        "## 7. Creación de tabla para visualización \"Reserva hídrica (hm3) entre los años 2012 y 2022\"\n",
        "\n",
        "Generamos **una nueva tabla de datos** preparada para alimentar la herramienta de visualización que vamos a utilizar, Google Data Studio.\n",
        "\n",
        "Para ello partimos del **dataset filtrado** en el apartado anterior. **Agrupamos** las variables por embalse, **calculamos la media** de los registros del volumen de agua y **renombramos** la nueva variable.\n",
        "\n",
        "\n",
        "*   Para agrupar las varibles utilizamos la función [.groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
        "\n",
        "*   Para renombrar las variables utilizamos las funciones [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG8NYE_t5hrW"
      },
      "outputs": [],
      "source": [
        "# Agrupamos el dataset por nombre del embalse y generamos una columna con la media del volumen\n",
        "tabla_vol = round(tabla_lin.groupby([\"demarcacion_hidrografica\", \"embalse_nombre\"])[\"volumen_actual\"].mean().reset_index(),2)\n",
        "\n",
        "# Renombramos la nueva columna generada\n",
        "tabla_vol = tabla_vol.rename(columns= {\"volumen_actual\": \"volumen_medio_10\"})\n",
        "tabla_vol.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lumwtt_g2vPY"
      },
      "source": [
        "Una vez generada la tabla **\"tabla_vol\"** la visualizamos para comprobar que los datos son correctos. En este caso se comprueba que se ha calculado el valor medio de volumen de agua por embalse y ha sido almacenada en una nueva variable \"**\"volumen_medio_10\"**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNhGEDLE1JOp"
      },
      "source": [
        "## 8. Creación de tabla para visualización \"Reserva hídrica (%) entre los años 2012 y 2022\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MYHVdimoxHb"
      },
      "source": [
        "Generamos una **nueva tabla de datos** preparada para alimentar la herramienta de visualización que vamos a utilizar, Google Data Studio.\n",
        "\n",
        "Para ello partimos del **dataset filtrado** en el apartado anterior. **Agrupamos** las variables por embalse, **calculamos la media** de los registros del porcentaje de llenado y **renombramos** la nueva variable.\n",
        "\n",
        "\n",
        "*   Para agrupar las varibles utilizamos la función [.groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
        "\n",
        "*   Para renombrar las variables utilizamos las funciones [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciG0LDOX2axa"
      },
      "outputs": [],
      "source": [
        "# Agrupamos el dataset por nombre del embalse y generamos una columna con la media del porcentaje\n",
        "tabla_por = round(tabla_lin.groupby([\"demarcacion_hidrografica\", \"embalse_nombre\"])[\"porcentaje_actual\"].mean().reset_index(),2)\n",
        "\n",
        "# Renombramos la nueva columna generada\n",
        "tabla_por = tabla_por.rename(columns= {\"porcentaje_actual\": \"porcentaje_medio_10\"})\n",
        "tabla_por.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OuTSrX65DHM"
      },
      "source": [
        "Una vez generada la tabla **\"tabla_por\"** la visualizamos para comprobar que los datos son correctos. En este caso se comprueba que ha sido calculado el valor medio de porcentaje de llenado por embalse y ha sido almacenado en una nueva variable \"**\"porcentaje_medio_10\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEkubFARRTYf"
      },
      "source": [
        "## 9. Creación de tabla para visualización \"Evolución mensual de la reserva hídrica (hm3)\"\n",
        "\n",
        "Generamos una **nueva tabla de datos** preparada para alimentar la herramienta de visualización que vamos a utilizar, **Google Data Studio**.\n",
        "\n",
        "Esta tabla contiene los datos medios de volumen de agua embalsada por mes para distintas series temporales. Esta series temporales corresponden a los años **2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020 y 2021**.\n",
        "\n",
        "Para ello partimos del **dataset filtrado en el apartado 5** con los datos pertenecientes al periodo temporal entre el 01/01/2012 y el 01/01/2022. Una vez filtrado, **agrupamos** las variables por embalse y mes, **calculamos la media** de los registros del volumen de agua y **renombramos** la nueva variable.\n",
        "\n",
        "\n",
        "*   Para agrupar las varibles utilizamos la función [groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)\n",
        "\n",
        "*   Para renombrar las variables utilizamos la funciones [.rename()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)\n",
        "\n",
        "*   Para unir las tablas en utilizamos la función [.merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uuJU2lk6yKI"
      },
      "outputs": [],
      "source": [
        "# Creamos una lista con las fechas iniciales y finales de las series temporales\n",
        "lista = [\"01/01/2012\", \"01/01/2013\", \"01/01/2014\", \"01/01/2015\", \"01/01/2016\", \"01/01/2017\", \"01/01/2018\", \"01/01/2019\", \"01/01/2020\", \"01/01/2021\", \"01/01/2022\"]\n",
        "\n",
        "# Creamos un bucle que recorra la lista anterior\n",
        "for i in range(len(lista)-1):\n",
        "    # Filtramos el dataset con los datos correspondientes a cada una de las series temporales\n",
        "    tabla_mini = tabla_lin[(embalses[\"fecha\"] > lista[i]) & (embalses[\"fecha\"]<lista[i+1])]\n",
        "    # Agrupamos el dataset por demarcación hidrográfica, nombre del embalse y mes. Generamos una columna con la media del volumen\n",
        "    lin = tabla_mini.groupby([\"demarcacion_hidrografica\",\"embalse_nombre\", \"mes\"])[\"volumen_actual\"].mean().reset_index()\n",
        "    # Renombramos la nueva columna generada con el valor medio\n",
        "    lin = lin.rename(columns= {\"volumen_actual\": lista[i].split(\"/\")[2]})\n",
        "\n",
        "    # Unificamos los datos de las distintas series temporales en una misma tabla\n",
        "    if i == 0:\n",
        "      tabla_lin_mes = lin\n",
        "    else:\n",
        "      tabla_lin_mes = tabla_lin_mes.merge(lin, on=[\"demarcacion_hidrografica\",\"embalse_nombre\",\"mes\"], how = \"inner\")\n",
        "\n",
        "tabla_lin_mes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OByVfD97GqF"
      },
      "source": [
        "Una vez generada la tabla **\"tabla_lin_mes\"** la visualizamos para comprobar que los datos son correctos. En este caso se comprueba que los datos del \"volumen_actual\" han sido agrupados por **mes** y en las **distintas series temporales** previamente especificadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKe2E_R3nIP1"
      },
      "source": [
        "## 10. Guardado de las tablas para la generación de la visualización.\n",
        "\n",
        "Una vez que tenemos las tablas con la estructura y variables que nos interesan para realizar la visualización de los datos, lo guardaremos como archivo de datos en formato **CSV** para posteriormente realizar otros análisis estadísticos o utilizarlo en otras herramientas de visualización de datos como la que abordamos a continuación. Es importante guardarlo con una codificación **UTF-8** (Formato de Transformación Unicode) para que los caracteres especiales sean identificados de manera correcta por cualquier software.\n",
        "\n",
        "*   Para guardar las tablas como archivos CSV utilizamos la función [.to_csv()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCWv-S6AscQE"
      },
      "outputs": [],
      "source": [
        "# Guardamos las tablas como archivos csv.\n",
        "tabla_lin.to_csv(\"lineas.csv\", index = False, encoding = \"utf-8\")\n",
        "tabla_vol.to_csv(\"volumen.csv\", index = False, encoding = \"utf-8\")\n",
        "tabla_por.to_csv(\"porcentaje.csv\", index = False, encoding = \"utf-8\")\n",
        "tabla_lin_mes.to_csv(\"lineas_mensual.csv\", index = False, encoding = \"utf-8\")\n",
        "embalses_geo.to_csv(\"geo.csv\", index = False, encoding = \"utf-8\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQXL49kOqJjW"
      },
      "source": [
        "Una vez generados los archivos, en el menú desplegable de la izquierda de esta pantalla, en la sección \"Archivos\" (el icono de la carpeta), encontraremos los archivos que acabamos de guardar dentro de la carpeta \"sample_data\". Usando el menú contextual, los ficheros pueden ser descargados.\n",
        "\n",
        "No obstante, dispones de estos conjuntos de datos preprocesados en esta carpeta del Laboratorio de datos del GitHub de datos.gob.es.\n",
        "\n",
        "A contintuación, puedes seguir los siguientes pasos para visualizar los datos que acabamos de preprocesar utilizando la herramienta Google Data Studio en el post *(añadir nombre y enlace al post)*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Análisis del estado y evolución de los embalses de agua nacionales.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}